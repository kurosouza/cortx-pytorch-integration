{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "special-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import logging\n",
    "import shutil\n",
    "import threading\n",
    "from botocore.client import Config\n",
    "from matplotlib import pyplot as plt\n",
    "from botocore.exceptions import ClientError\n",
    "from boto3.s3.transfer import TransferConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "correct-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_POINT_URL = 'http://uvo17qqh4jn92xmchpj.vm.cld.sr'\n",
    "A_KEY = 'AKIAtEpiGWUcQIelPRlD1Pi6xQ'\n",
    "S_KEY = 'YNV6xS8lXnCTGSy1x2vGkmGnmdJbZSapNXaSaRhK'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-service",
   "metadata": {},
   "source": [
    "TODO: Move to separate class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "neither-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressPercentage(object):\n",
    "    def __init__(self, filename):\n",
    "        self._filename = filename\n",
    "        self._size = float(os.path.getsize(filename))\n",
    "        self._seen_so_far = 0\n",
    "        self._lock = threading.Lock()\n",
    "        \n",
    "    def __call__(self, bytes_amount):\n",
    "        # To simplify, assume this is hooked up to a single filename\n",
    "        with self._lock:\n",
    "            self._seen_so_far += bytes_amount\n",
    "            percentage = (self._seen_so_far / self._size) * 100\n",
    "            sys.stdout.write(\"\\r%s  %s / %s  (%.2f%%)\" %\n",
    "                             (self._filename, self._seen_so_far, \n",
    "                              self._size, percentage))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "def multipart_upload_with_s3(bucket_name, file_path=None, object_name=None):\n",
    "    # Multipart upload (see notes)\n",
    "    config = TransferConfig(multipart_threshold=1024 * 25, max_concurrency=10,\n",
    "                            multipart_chunksize=1024 * 25, use_threads=True)\n",
    "    key_path = 'multipart_files/{}'.format(object_name)\n",
    "    print(bucket_name,file_path,object_name,key_path)\n",
    "    s3_client.upload_file(file_path, bucket_name, key_path,\n",
    "                          ExtraArgs={'ACL': 'public-read', \n",
    "                                     'ContentType': 'text/pdf'},\n",
    "                          Config=config, Callback=ProgressPercentage(file_path))\n",
    "    \n",
    "def multipart_download_with_s3(bucket_name, file_path=None, object_name=None):\n",
    "    config = TransferConfig(multipart_threshold=1024 * 25, max_concurrency=10,\n",
    "                            multipart_chunksize=1024 * 25, use_threads=True)\n",
    "    temp_file = os.path.dirname(__file__)\n",
    "    s3_resource.Object(bucket_name, \n",
    "                       object_name\n",
    "                       ).download_file(file_path, Config=config,\n",
    "                                       Callback=ProgressPercentage(temp_file))\n",
    "\n",
    "\"\"\"Functions for buckets operation\"\"\"\n",
    "def create_bucket_op(bucket_name, region):\n",
    "    if region is None:\n",
    "        s3_client.create_bucket(Bucket=bucket_name)\n",
    "    else:\n",
    "        location = {'LocationConstraint': region}\n",
    "        s3_client.create_bucket(Bucket=bucket_name, \n",
    "                                CreateBucketConfiguration=location)\n",
    "\n",
    "def list_bucket_op(bucket_name, region, operation):\n",
    "    buckets = s3_client.list_buckets()\n",
    "    if buckets['Buckets']:\n",
    "        for bucket in buckets['Buckets']:\n",
    "            print(bucket)\n",
    "            return True\n",
    "    else:\n",
    "        logging.error('unknown bucket operation')\n",
    "        return False\n",
    "    \n",
    "def bucket_operation(bucket_name, region=None, operation='list'):\n",
    "    try:\n",
    "        if operation == 'delete':\n",
    "            s3_client.delete_bucket(Bucket=bucket_name)\n",
    "        elif operation == 'create':\n",
    "            create_bucket_op(bucket_name, region)\n",
    "        elif operation == 'list':\n",
    "            return list_bucket_op(bucket_name, region, operation)\n",
    "        else:\n",
    "            logging.error('unknown bucket operation')\n",
    "            return False\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\"\"\"Functions for objects operation\"\"\"\n",
    "def list_object_op(bucket_name):\n",
    "     s3_objects = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "     if s3_objects.get('Contents'):\n",
    "         for obj in s3_objects['Contents']:\n",
    "             print(obj)\n",
    "\n",
    "def delete_object_op(bucket_name, object_name, operation):\n",
    "    if not object_name:\n",
    "        logging.error('object_name missing for {}'.format(operation))\n",
    "        return False  \n",
    "    s3_client.delete_object(Bucket=bucket_name, Key=object_name)\n",
    "    return True\n",
    "\n",
    "def upload_download_object_op(bucket_name, object_name, file_path, operation):\n",
    "    if not file_path or not object_name:\n",
    "        logging.error('file_path and/or object_name missing for upload')\n",
    "        return False\n",
    "    if operation == 'upload':\n",
    "        multipart_upload_with_s3(bucket_name=bucket_name, file_path=file_path,\n",
    "                                 object_name=object_name)\n",
    "    else:\n",
    "        multipart_download_with_s3(bucket_name=bucket_name, file_path=file_path,\n",
    "                                   object_name=object_name)\n",
    "    return True\n",
    "\n",
    "def object_operation(bucket_name=None, object_name=None, file_path=None,\n",
    "                     operation='list'):                                                             \n",
    "    try:\n",
    "        if not bucket_name:\n",
    "            logging.error('The bucket name %s is missing for %s operation!'\n",
    "                          % (bucket_name, operation))\n",
    "            return False\n",
    "        if operation == 'list':\n",
    "            list_object_op(bucket_name)\n",
    "        elif operation == 'delete':\n",
    "            return delete_object_op(bucket_name, object_name, operation)\n",
    "        elif operation == 'upload' or operation == 'download':\n",
    "            return upload_download_object_op(bucket_name, object_name,\n",
    "                                             file_path, operation)      \n",
    "        else:\n",
    "            logging.error('unknown object operation')\n",
    "            return False\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\"\"\"Functions for files operation\"\"\"\n",
    "def list_op_file(bucket_name):\n",
    "    current_bucket = s3_resource.Bucket(bucket_name)\n",
    "    print('The files in bucket %s:\\n' % (bucket_name))\n",
    "    for obj in current_bucket.objects.all():\n",
    "        print(obj.meta.data) \n",
    "        \n",
    "    return True\n",
    "\n",
    "def delete_op_file(bucket_name, file_name, operation):\n",
    "    if not file_name:\n",
    "        logging.error('The file name %s is missing for%s operation!' \n",
    "                      % (file_name, operation))\n",
    "        return False\n",
    "    s3_client.delete_object(Bucket=bucket_name, Key=file_name)\n",
    "    return True\n",
    "    \n",
    "def upload_download_op_file(bucket_name, file_name, file_location,\n",
    "                            region, operation):\n",
    "    if not file_location:\n",
    "        logging.error('The file location %d is missing for %s operation!'\n",
    "                      % (file_location, operation))\n",
    "        return False\n",
    "    if operation == 'download':\n",
    "        s3_resource.Bucket(bucket_name).download_file(file_name, file_location)\n",
    "    elif operation == 'upload' and region is None:\n",
    "        s3_resource.Bucket(bucket_name).upload_file(file_location, file_name)\n",
    "    else:\n",
    "         location = {'LocationConstraint': region}\n",
    "         s3_resource.Bucket(bucket_name\n",
    "                            ).upload_file(file_location, file_name,\n",
    "                                          CreateBucketConfiguration=location) \n",
    "    return True\n",
    "    \n",
    "def file_operation(bucket_name=None, file_name=None, file_location=None, \n",
    "                   region=None, operation='list'):\n",
    "    if not bucket_name:\n",
    "        logging.error('The bucket name is %s missing!' % (bucket_name))\n",
    "        return False \n",
    "    try:\n",
    "        if operation == 'list':\n",
    "            return list_op_file(bucket_name)\n",
    "        elif operation == 'delete':\n",
    "            return delete_op_file(bucket_name, file_name, operation)  \n",
    "        elif operation == 'upload' or operation == 'download':\n",
    "            return upload_download_op_file(bucket_name, file_name, \n",
    "                                           file_location, region, operation)\n",
    "        else:\n",
    "            logging.error('unknown file operation')\n",
    "            return False  \n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "artistic-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3', endpoint_url=END_POINT_URL,\n",
    "                             aws_access_key_id=A_KEY,\n",
    "                             aws_secret_access_key=S_KEY,\n",
    "                             config=Config(signature_version='s3v4'),\n",
    "                             region_name='US')\n",
    "\n",
    "s3_client = boto3.client('s3', endpoint_url=END_POINT_URL,\n",
    "                         aws_access_key_id=A_KEY,\n",
    "                         aws_secret_access_key=S_KEY,\n",
    "                         config=Config(signature_version='s3v4'),\n",
    "                         region_name='US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "homeless-stadium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files in bucket testbucket:\n",
      "\n",
      "{'Key': 'PennFudanPed.zip', 'LastModified': datetime.datetime(2021, 4, 27, 13, 17, 28, tzinfo=tzutc()), 'ETag': '\"f0c664d97f7b031b9394255fa323543f-7\"', 'Size': 53723336, 'StorageClass': 'STANDARD', 'Owner': {'DisplayName': 'S3user', 'ID': 'e500ea6b45f64f068ab001b7f1fdfc57ed2faed247474d81b66f69a6233727c8'}}\n",
      "{'Key': 'multipart_files/randomfile.txt', 'LastModified': datetime.datetime(2021, 4, 27, 7, 59, 15, tzinfo=tzutc()), 'ETag': '\"9d37ffb157b1d1a31ec0220f1095a926\"', 'Size': 13, 'StorageClass': 'STANDARD', 'Owner': {'DisplayName': 'S3user', 'ID': 'e500ea6b45f64f068ab001b7f1fdfc57ed2faed247474d81b66f69a6233727c8'}}\n",
      "{'Key': 'randomfile.txt', 'LastModified': datetime.datetime(2021, 4, 27, 7, 50, 55, tzinfo=tzutc()), 'ETag': '\"9d37ffb157b1d1a31ec0220f1095a926\"', 'Size': 13, 'StorageClass': 'STANDARD', 'Owner': {'DisplayName': 'S3user', 'ID': 'e500ea6b45f64f068ab001b7f1fdfc57ed2faed247474d81b66f69a6233727c8'}}\n"
     ]
    }
   ],
   "source": [
    "files = list_op_file('testbucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'testbucket'\n",
    "file_name = 'randomfile.txt'\n",
    "path_file_upload = '/home/dreamchild/randomfile.txt'\n",
    "path_file_download = '/tmp/randomfile.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('random file {} and {}'.format(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_operation(bucket_name, file_name, path_file_upload, None, 'upload'):\n",
    "    print('file {} uploaded successfully'.format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-harassment",
   "metadata": {},
   "source": [
    "Upload dataset to Cortx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-uniform",
   "metadata": {},
   "source": [
    "## Setup filename and data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "announced-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'testbucket'\n",
    "file_name = 'PennFudanPed.zip'\n",
    "path_file_upload = '/home/dreamchild/sgcortex/data/{}'.format(file_name)\n",
    "path_file_download = '/home/dreamchild/sgcortex/tmp/{}'.format(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-minneapolis",
   "metadata": {},
   "source": [
    "Upload to Cortx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "seventh-alexander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file PennFudanPed.zip uploaded to Cortx\n"
     ]
    }
   ],
   "source": [
    "if file_operation(bucket_name, file_name, path_file_upload, None, 'upload'):\n",
    "    print('file {} uploaded to Cortx'.format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-overview",
   "metadata": {},
   "source": [
    "### List files in bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "electrical-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files in bucket testbucket:\n",
      "\n",
      "{'Key': 'PennFudanPed.zip', 'LastModified': datetime.datetime(2021, 4, 27, 13, 17, 28, tzinfo=tzutc()), 'ETag': '\"f0c664d97f7b031b9394255fa323543f-7\"', 'Size': 53723336, 'StorageClass': 'STANDARD', 'Owner': {'DisplayName': 'S3user', 'ID': 'e500ea6b45f64f068ab001b7f1fdfc57ed2faed247474d81b66f69a6233727c8'}}\n",
      "{'Key': 'multipart_files/randomfile.txt', 'LastModified': datetime.datetime(2021, 4, 27, 7, 59, 15, tzinfo=tzutc()), 'ETag': '\"9d37ffb157b1d1a31ec0220f1095a926\"', 'Size': 13, 'StorageClass': 'STANDARD', 'Owner': {'DisplayName': 'S3user', 'ID': 'e500ea6b45f64f068ab001b7f1fdfc57ed2faed247474d81b66f69a6233727c8'}}\n",
      "{'Key': 'randomfile.txt', 'LastModified': datetime.datetime(2021, 4, 27, 7, 50, 55, tzinfo=tzutc()), 'ETag': '\"9d37ffb157b1d1a31ec0220f1095a926\"', 'Size': 13, 'StorageClass': 'STANDARD', 'Owner': {'DisplayName': 'S3user', 'ID': 'e500ea6b45f64f068ab001b7f1fdfc57ed2faed247474d81b66f69a6233727c8'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_op_file('testbucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = object_operation(bucket_name, object_name=file_name, file_path=path_file_upload, operation='upload')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-swimming",
   "metadata": {},
   "source": [
    "download from cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "solar-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file PennFudanPed.zip downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "if file_operation(bucket_name, file_name, path_file_download, None, operation='download'):\n",
    "    print('file {} downloaded successfully.'.format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-civilian",
   "metadata": {},
   "source": [
    "## unzip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "permanent-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "headed-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(path_file_download, 'r') as dataset_zip_file:\n",
    "    dataset_zip_file.extractall('/home/dreamchild/sgcortex/data/unzipped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-suicide",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "purple-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class PennFudanDataset(object):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"PNGImages\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"PedMasks\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path)\n",
    "        mask = np.array(mask)\n",
    "        obj_ids = np.unique(mask)\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-medicare",
   "metadata": {},
   "source": [
    "### setup pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "italian-motor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /home/dreamchild/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a1def9a83347368ae167a8ff0a1636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=167502836.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# load a model pre-trained pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "num_classes = 2\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-burner",
   "metadata": {},
   "source": [
    "### change model backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caring-market",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /home/dreamchild/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290d150e752247d8a68f051992518fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=14212972.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
    "backbone.out_channels = 1280\n",
    "\n",
    "anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                   aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
    "                                                output_size=7,\n",
    "                                                sampling_ratio=2)\n",
    "\n",
    "\n",
    "model = FasterRCNN(backbone,\n",
    "                   num_classes=2,\n",
    "                   rpn_anchor_generator=anchor_generator,\n",
    "                   box_roi_pool=roi_pooler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-automation",
   "metadata": {},
   "source": [
    "### setup instance segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "standing-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    \n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    \n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-thing",
   "metadata": {},
   "source": [
    "### data augmentation helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "great-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "through-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-snowboard",
   "metadata": {},
   "source": [
    "### testing the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "variable-confirmation",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/dreamchild/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/dreamchild/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/dreamchild/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-8-7c503c66062b>\", line 53, in __getitem__\n    img, target = self.transforms(img, target)\nTypeError: __call__() takes 2 positional arguments but 3 were given\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c8efdcf0957b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# For Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/dreamchild/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/dreamchild/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/dreamchild/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-8-7c503c66062b>\", line 53, in __getitem__\n    img, target = self.transforms(img, target)\nTypeError: __call__() takes 2 positional arguments but 3 were given\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "dataset = PennFudanDataset('/home/dreamchild/sgcortex/data/unzipped/PennFudanPed', get_transform(train=True))\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4)\n",
    "# For Training\n",
    "images,targets = next(iter(data_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "output = model(images,targets)   # Returns losses and detections\n",
    "# For inference\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)           # Returns predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-terrace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "touched-citizenship",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision.engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d07aa4eeb8fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# train on the GPU or on the CPU, if a GPU is not available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.engine'"
     ]
    }
   ],
   "source": [
    "from torchvision.engine import train_one_epoch, evaluate\n",
    "import torch.utils as utils\n",
    "\n",
    "def main():\n",
    "    # train on the GPU or on the CPU, if a GPU is not available\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # our dataset has two classes only - background and person\n",
    "    num_classes = 2\n",
    "    # use our dataset and defined transformations\n",
    "    dataset = PennFudanDataset('PennFudanPed', get_transform(train=True))\n",
    "    dataset_test = PennFudanDataset('PennFudanPed', get_transform(train=False))\n",
    "\n",
    "    # split the dataset in train and test set\n",
    "    indices = torch.randperm(len(dataset)).tolist()\n",
    "    dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "    dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "    # define training and validation data loaders\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=2, shuffle=True, num_workers=4,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "    # get the model using our helper function\n",
    "    model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "    # move model to the right device\n",
    "    model.to(device)\n",
    "\n",
    "    # construct an optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "    # and a learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=3,\n",
    "                                                   gamma=0.1)\n",
    "\n",
    "    # let's train it for 10 epochs\n",
    "    num_epochs = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train for one epoch, printing every 10 iterations\n",
    "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "        # evaluate on the test dataset\n",
    "        evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "    print(\"That's it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "given-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-communist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
